{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ë§¥ë½ ë³´ì¡´ ê°œì„ ëœ RAG Chain ìƒì„±\n",
        "\n",
        "ìŠ¤í™ê³¼ ê·œê²©ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ ê°œì„ ëœ í…ìŠ¤íŠ¸ ë¶„í•  ë°©ì‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from typing import List, Dict, Any\n",
        "from pathlib import Path\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë§ˆí¬ë‹¤ìš´ íŒŒì¼ í¬ê¸°: 112832 ë¬¸ì\n",
            "ì²« 500ì: # ì›ìŠ¤í† ì–´ ì¸ì•± ê²°ì œ ì—°ë™ ê°€ì´ë“œ\n",
            "\n",
            "## ì›ìŠ¤í† ì–´ In-App SDK\n",
            "ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œëŠ” ë‹¤ì–‘í•œ ê²°ì œìˆ˜ë‹¨ê³¼ ê°•ë ¥í•œ ë³´ì•ˆ ê·¸ë¦¬ê³  í¸ë¦¬í•˜ê³  ì•ˆì „í•œ ê²°ì œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
            "\n",
            "- ìµœì‹ ë²„ì „ ì¸ì•±ê²°ì œ ê°€ì´ë“œ\n",
            "[ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ API V7 (SDK V21) ì•ˆë‚´ ë° ë‹¤ìš´ë¡œë“œ](#ì›ìŠ¤í† ì–´-ì¸ì•±ê²°ì œ-api-v7sdk-v21-ì—°ë™-ì•ˆë‚´-ë°-ë‹¤ìš´ë¡œë“œ)\n",
            "\n",
            "## ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ API V7(SDK V21) ì—°ë™ ì•ˆë‚´ ë° ë‹¤ìš´ë¡œë“œ\n",
            "ì›ìŠ¤í† ì–´ì˜ ìµœì‹  ì¸ì•±ê²°ì œ API V7(SDK V21)ì´ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ë³´ë‹¤ ê°•ë ¥í•˜ê³  ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì§€ì›í•˜ëŠ” ìµœì‹  ë²„ì „ì„ ì ìš©í•´ë³´ì„¸ìš”.\n",
            "\n",
            "- API V4(SDK V16) ì´í•˜ ë²„ì „ê³¼ëŠ” í˜¸í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¸ì•±ê²°ì œ API V4(SDK V16)ì— ëŒ€í•œ ì•ˆë‚´ ë° ë‹¤ìš´ë¡œë“œëŠ” ì—¬ê¸°ë¥¼ í´ë¦­í•´ì£¼ì„¸ìš”.\n",
            "- í˜„ì¬ íŒë§¤ì¤‘ì¸ ì•±ì„ ëŒ€í•œë¯¼êµ­ ì™¸ êµ­ê°€/ì§€ì—­ìœ¼ë¡œ ë°°í¬í•˜ê¸° ìœ„í•´ì„œëŠ” ì•„ë˜ ê°€ì´ë“œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”\n",
            "  - [ëŒ€í•œë¯¼êµ­ ì™¸ êµ­ê°€ ë° ì§€ì—­ ë°°í¬ë¥¼ ìœ„í•œ ê°€ì´ë“œ](https://onestore-de...\n"
          ]
        }
      ],
      "source": [
        "def load_markdown_file(file_path: str) -> str:\n",
        "    \"\"\"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "# ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë“œ\n",
        "md_content = load_markdown_file(\"data/dev_center_guide_touched.md\")\n",
        "print(f\"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ í¬ê¸°: {len(md_content)} ë¬¸ì\")\n",
        "print(f\"ì²« 500ì: {md_content[:500]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë§¥ë½ ë³´ì¡´ ë¶„í•  ì™„ë£Œ: 209ê°œ ì²­í¬\n",
            "ë¬¸ì„œ 134: . PNS (Push Notification Service) ì´ìš©í•˜ê¸°\n",
            "#### ê°œìš” \n",
            "ì›ìŠ¤í† ì–´ëŠ” ê°œë°œìë¥¼ ìœ„í•´ ë‘ ê°€ì§€ Push Notification Serviceë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
            "* PNSëŠ” Push Notification Serviceì˜ ì•½ìì…ë‹ˆë‹¤.\n",
            "* PNSëŠ” ëª¨ë°”ì¼ì˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¶ˆì•ˆì •ì„±ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ê°œë°œì‚¬ê°€ ì§€ì •í•œ ì„œë²„ë¡œ ê°œë³„ ì‚¬ìš©ìì˜ ê²°ì œ ...\n",
            "í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "ë¶„í•  ë°©ë²•: recursive_split\n",
            "--------------------------------------------------\n",
            "ë¬¸ì„œ 135: . \n",
            "ì •ìƒì ì¸ ê²°ì œ ê±´ì¸ì§€ Server to Serverë¡œ í™•ì¸í•˜ê¸°ë¥¼ ì›í•˜ì‹ ë‹¤ë©´ PNS notificationì„ ì´ìš©í•˜ëŠ” ëŒ€ì‹ , ê´€ë ¨ ì„œë²„ APIë¡œ ì¡°íšŒí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
            "ì›ìŠ¤í† ì–´ëŠ” ê²€ì¦ ë° ëª¨ë‹ˆí„°ë§ ëª©ì ìœ¼ë¡œ ê²°ì œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìœ¼ë©°, í•´ë‹¹ í…ŒìŠ¤íŠ¸ ê±´ë“¤ë„ ê²°ì œ/ê²°ì œì·¨ì†Œ ì‹œ ë™ì¼í•˜ê²Œ notificationì´ ë°œì†¡ë©ë‹ˆë‹¤. ì›ìŠ¤í† ì–´ê°€ ì§„í–‰í•œ ê²°ì œ í…ŒìŠ¤...\n",
            "í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "ë¶„í•  ë°©ë²•: recursive_split\n",
            "--------------------------------------------------\n",
            "ë¬¸ì„œ 153: , \"description\": \"ì •ê¸° ê²°ì œ ì¼ì‹œ ì¤‘ì§€ ì¼ì •ì´ ë³€ê²½ ë˜ì—ˆìŠµë‹ˆë‹¤.\"},\n",
            "  {\"subscriptionStatus\": \"12\", \"subscriptionCode\": \"SUBSCRIPTION_REVOKED\", \"description\": \"ì •ê¸° ê²°ì œê°€ ì¦‰ì‹œ í•´ì§€ ë˜ì—ˆìŠµë‹ˆë‹¤.\"},\n",
            "  {\"subscriptionStatus\": \"13\", \"subscri...\n",
            "í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "ë¶„í•  ë°©ë²•: recursive_split\n",
            "--------------------------------------------------\n",
            "ë¬¸ì„œ 158: . ê´€ë ¨ ë‚´ìš©ì€ PNS(Push Notification Service) ì´ìš©í•˜ê¸°ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
            "\n",
            "#### ì •ê¸° ê²°ì œ êµ¬ë§¤ \n",
            "ì‚¬ìš©ìê°€ ì •ê¸° ê²°ì œë¥¼ êµ¬ë§¤í•˜ë©´ PurchaseClient.queryPurchasesAsync()ì—ì„œ ì •ê¸° ê²°ì œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ê³ , SUBSCRIPTION_PURCHASEDì¸ SubscriptionNotificationì´ ì „ì†¡ë©ë‹ˆë‹¤. \n",
            "\n",
            "...\n",
            "í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "ë¶„í•  ë°©ë²•: recursive_split\n",
            "--------------------------------------------------\n",
            "ë¬¸ì„œ 205: , \"v6ApiURI\": null, \"ë³€ê²½ì‚¬í•­\": \"ì›”ì •ì•¡ ìƒí’ˆ êµ¬ë§¤ ìƒì„¸ì¡°íšŒ API ë¡œ í†µí•©\"}\n",
            "]\n",
            "\n",
            "- ì¶”ê°€\n",
            "[\n",
            "  {\"feature\": \"êµ¬ë§¤ í™•ì¸\", \"V5ApiURI\": null, \"v6ApiURI\": \"/v6/apps/{packageName}/purchases/all/products/\n",
            "{productId}/{purchaseToken}/acknow...\n",
            "í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "ë¶„í•  ë°©ë²•: recursive_split\n",
            "--------------------------------------------------\n",
            "ë¬¸ì„œ 206: . \n",
            "\n",
            "ìƒì„¸í•œ ê·œê²©ì€ PNS ë©”ì‹œì§€ ìƒì„¸ ë³€ê²½ ë‚´ì—­ì—ì„œ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
            "\n",
            "#### ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ë¼ì´ë¸ŒëŸ¬ë¦¬ API V5(SDK V17) \n",
            "- API ë²„ì „ì€ ê°œë°œì‚¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ 'AndroidManifest.xml' íŒŒì¼ì— ì•„ë˜ì™€ ê°™ì´ ëª…ì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
            "- ìì„¸í•œ ë‚´ìš©ì€ ì¸ì•±ê²°ì œ ì ìš©ì„ ìœ„í•œ ì‚¬ì „ì¤€ë¹„ í˜ì´ì§€ì˜ 'Android Manifest...\n",
            "í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "ë¶„í•  ë°©ë²•: recursive_split\n",
            "--------------------------------------------------\n",
            "\\nì´ 6ê°œì˜ ë¬¸ì„œì—ì„œ 'PNS' ë°œê²¬\n",
            "í‰ê·  ì²­í¬ í¬ê¸°: 580 ë¬¸ì\n",
            "ìµœì†Œ ì²­í¬ í¬ê¸°: 2 ë¬¸ì\n",
            "ìµœëŒ€ ì²­í¬ í¬ê¸°: 800 ë¬¸ì\n"
          ]
        }
      ],
      "source": [
        "def context_preserving_split(md_text: str, chunk_size: int = 800, chunk_overlap: int = 150) -> List[Document]:\n",
        "    \"\"\"\n",
        "    ë§¥ë½ ë³´ì¡´ ë¶„í•  í•¨ìˆ˜\n",
        "    - ë” í° ì²­í¬ í¬ê¸°ë¡œ ë¶„í• í•˜ì—¬ ë§¥ë½ ë³´ì¡´\n",
        "    - ìŠ¤í™ê³¼ ê·œê²©ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ ê°œì„ \n",
        "    - í—¤ë” ê¸°ë°˜ ë¶„í•  ìš°ì„  ì ìš©\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1ë‹¨ê³„: ì½”ë“œ ë¸”ë¡ ë³´ì¡´í•˜ë©´ì„œ ë¶„í• \n",
        "    # ì½”ë“œ ë¸”ë¡ì„ ì„ì‹œë¡œ ë§ˆìŠ¤í‚¹\n",
        "    code_blocks = {}\n",
        "    counter = 0\n",
        "    \n",
        "    def mask_code_block(match):\n",
        "        nonlocal counter\n",
        "        placeholder = f\"__CODE_BLOCK_{counter}__\"\n",
        "        code_blocks[placeholder] = match.group(0)\n",
        "        counter += 1\n",
        "        return placeholder\n",
        "    \n",
        "    # ì½”ë“œ ë¸”ë¡ ë§ˆìŠ¤í‚¹\n",
        "    masked_text = re.sub(r'```[\\\\s\\\\S]*?```', mask_code_block, md_text)\n",
        "    \n",
        "    # 2ë‹¨ê³„: í—¤ë” ê¸°ë°˜ ë¶„í•  ìš°ì„  ì ìš©\n",
        "    documents = []\n",
        "    current_chunk = \"\"\n",
        "    current_header = \"\"\n",
        "    \n",
        "    lines = masked_text.split('\\\\n')\n",
        "    i = 0\n",
        "    \n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "        \n",
        "        # í—¤ë” ë°œê²¬ ì‹œ ìƒˆë¡œìš´ ì²­í¬ ì‹œì‘\n",
        "        if line.strip().startswith('#'):\n",
        "            # ì´ì „ ì²­í¬ê°€ ìˆìœ¼ë©´ ì €ì¥\n",
        "            if current_chunk.strip():\n",
        "                # ì½”ë“œ ë¸”ë¡ ë³µì›\n",
        "                restored_chunk = current_chunk\n",
        "                for placeholder, code_block in code_blocks.items():\n",
        "                    if placeholder in current_chunk:\n",
        "                        restored_chunk = restored_chunk.replace(placeholder, code_block)\n",
        "                \n",
        "                # í‚¤ì›Œë“œ ì¶”ì¶œ\n",
        "                keywords = extract_keywords(restored_chunk)\n",
        "                \n",
        "                doc = Document(\n",
        "                    page_content=restored_chunk,\n",
        "                    metadata={\n",
        "                        \"type\": \"documentation\",\n",
        "                        \"source\": \"dev_center_guide_touched.md\",\n",
        "                        \"chunk_idx\": len(documents),\n",
        "                        \"chunk_size\": chunk_size,\n",
        "                        \"chunk_overlap\": chunk_overlap,\n",
        "                        \"header\": current_header,\n",
        "                        \"keywords\": keywords,\n",
        "                        \"has_code\": \"```\" in restored_chunk,\n",
        "                        \"has_function\": any(func in restored_chunk for func in [\"()\", \"function\", \"API\", \"launch\"]),\n",
        "                        \"split_method\": \"header_based\"\n",
        "                    }\n",
        "                )\n",
        "                documents.append(doc)\n",
        "            \n",
        "            # ìƒˆë¡œìš´ í—¤ë”ë¡œ ì‹œì‘\n",
        "            current_header = line.strip()\n",
        "            current_chunk = line + '\\\\n'\n",
        "            i += 1\n",
        "            \n",
        "            # í—¤ë” ë‹¤ìŒ ë‚´ìš©ë“¤ì„ ìˆ˜ì§‘\n",
        "            while i < len(lines):\n",
        "                next_line = lines[i]\n",
        "                \n",
        "                # ë‹¤ìŒ í—¤ë”ë¥¼ ë§Œë‚˜ë©´ ì¤‘ë‹¨\n",
        "                if next_line.strip().startswith('#'):\n",
        "                    break\n",
        "                \n",
        "                current_chunk += next_line + '\\\\n'\n",
        "                i += 1\n",
        "                \n",
        "                # ì²­í¬ê°€ ë„ˆë¬´ ì»¤ì§€ë©´ ì¤‘ë‹¨ (ìŠ¤í™ ë³´ì¡´ì„ ìœ„í•´)\n",
        "                if len(current_chunk) > chunk_size * 2:\n",
        "                    break\n",
        "        else:\n",
        "            # ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬\n",
        "            current_chunk += line + '\\\\n'\n",
        "            i += 1\n",
        "    \n",
        "    # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬\n",
        "    if current_chunk.strip():\n",
        "        # ì½”ë“œ ë¸”ë¡ ë³µì›\n",
        "        restored_chunk = current_chunk\n",
        "        for placeholder, code_block in code_blocks.items():\n",
        "            if placeholder in current_chunk:\n",
        "                restored_chunk = restored_chunk.replace(placeholder, code_block)\n",
        "        \n",
        "        # í‚¤ì›Œë“œ ì¶”ì¶œ\n",
        "        keywords = extract_keywords(restored_chunk)\n",
        "        \n",
        "        doc = Document(\n",
        "            page_content=restored_chunk,\n",
        "            metadata={\n",
        "                \"type\": \"documentation\",\n",
        "                \"source\": \"dev_center_guide_touched.md\",\n",
        "                \"chunk_idx\": len(documents),\n",
        "                \"chunk_size\": chunk_size,\n",
        "                \"chunk_overlap\": chunk_overlap,\n",
        "                \"header\": current_header,\n",
        "                \"keywords\": keywords,\n",
        "                \"has_code\": \"```\" in restored_chunk,\n",
        "                \"has_function\": any(func in restored_chunk for func in [\"()\", \"function\", \"API\", \"launch\"]),\n",
        "                \"split_method\": \"header_based\"\n",
        "            }\n",
        "        )\n",
        "        documents.append(doc)\n",
        "    \n",
        "    # 3ë‹¨ê³„: í° ì²­í¬ë“¤ì„ ë‹¤ì‹œ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í•  (í•„ìš”ì‹œ)\n",
        "    final_documents = []\n",
        "    for doc in documents:\n",
        "        if len(doc.page_content) > chunk_size * 1.5:\n",
        "            # í° ì²­í¬ë¥¼ ë‹¤ì‹œ ë¶„í• \n",
        "            splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=chunk_size,\n",
        "                chunk_overlap=chunk_overlap,\n",
        "                separators=[\n",
        "                    \"\\\\n\\\\n\",  # ë¹ˆ ì¤„\n",
        "                    \"\\\\n\",    # ì¤„ë°”ê¿ˆ\n",
        "                    \". \",    # ë¬¸ì¥ ë\n",
        "                    \", \",    # ì‰¼í‘œ\n",
        "                    \" \",     # ê³µë°±\n",
        "                    \"\"       # ë¬¸ì ë‹¨ìœ„\n",
        "                ],\n",
        "                length_function=len,\n",
        "                is_separator_regex=False\n",
        "            )\n",
        "            \n",
        "            sub_chunks = splitter.split_text(doc.page_content)\n",
        "            for j, sub_chunk in enumerate(sub_chunks):\n",
        "                sub_doc = Document(\n",
        "                    page_content=sub_chunk,\n",
        "                    metadata={\n",
        "                        **doc.metadata,\n",
        "                        \"chunk_idx\": f\"{doc.metadata['chunk_idx']}_{j}\",\n",
        "                        \"split_method\": \"recursive_split\",\n",
        "                        \"parent_chunk\": doc.metadata['chunk_idx']\n",
        "                    }\n",
        "                )\n",
        "                final_documents.append(sub_doc)\n",
        "        else:\n",
        "            final_documents.append(doc)\n",
        "    \n",
        "    return final_documents\n",
        "\n",
        "def extract_keywords(text: str) -> List[str]:\n",
        "    \"\"\"í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
        "    keywords = []\n",
        "    \n",
        "    # í•¨ìˆ˜ëª… íŒ¨í„´ (ì˜ˆ: launchPurchaseFlow, queryProductDetailAsync)\n",
        "    function_pattern = r'\\\\b[a-zA-Z][a-zA-Z0-9]*\\\\([^)]*\\\\)'\n",
        "    functions = re.findall(function_pattern, text)\n",
        "    keywords.extend(functions)\n",
        "    \n",
        "    # API íŒ¨í„´\n",
        "    api_pattern = r'\\\\b[A-Z][A-Z0-9_]*\\\\b'\n",
        "    apis = re.findall(api_pattern, text)\n",
        "    keywords.extend(apis[:10])  # ìƒìœ„ 10ê°œë¡œ ì¦ê°€\n",
        "    \n",
        "    # íŠ¹ìˆ˜ í‚¤ì›Œë“œ (í™•ì¥)\n",
        "    special_keywords = [\n",
        "        \"launchPurchaseFlow\", \"queryProductDetailAsync\", \"PurchaseClient\",\n",
        "        \"IapResult\", \"PurchaseData\", \"ProductDetail\", \"PurchaseFlowParams\",\n",
        "        \"PNS\", \"SNS\", \"BillingClient\", \"BillingResult\", \"SubscriptionNotification\",\n",
        "        \"PurchaseFlowParams\", \"ProrationMode\", \"AuthManager\", \"PurchaseManager\"\n",
        "    ]\n",
        "    \n",
        "    for keyword in special_keywords:\n",
        "        if keyword.lower() in text.lower():\n",
        "            keywords.append(keyword)\n",
        "    \n",
        "    return list(set(keywords))  # ì¤‘ë³µ ì œê±°\n",
        "\n",
        "# ë§¥ë½ ë³´ì¡´ ë¶„í•  ì‹¤í–‰ (ë” í° ì²­í¬ í¬ê¸°)\n",
        "docs_context_preserved = context_preserving_split(md_content, chunk_size=800, chunk_overlap=150)\n",
        "print(f\"ë§¥ë½ ë³´ì¡´ ë¶„í•  ì™„ë£Œ: {len(docs_context_preserved)}ê°œ ì²­í¬\")\n",
        "\n",
        "# launchPurchaseFlow í¬í•¨ ë¬¸ì„œ í™•ì¸\n",
        "launch_docs = []\n",
        "for i, doc in enumerate(docs_context_preserved):\n",
        "    if 'PNS' in doc.page_content:\n",
        "        launch_docs.append((i, doc))\n",
        "        print(f\"ë¬¸ì„œ {i}: {doc.page_content[:200]}...\")\n",
        "        print(f\"í‚¤ì›Œë“œ: {doc.metadata.get('keywords', [])}\")\n",
        "        print(f\"ë¶„í•  ë°©ë²•: {doc.metadata.get('split_method', 'unknown')}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "print(f\"\\\\nì´ {len(launch_docs)}ê°œì˜ ë¬¸ì„œì—ì„œ 'PNS' ë°œê²¬\")\n",
        "\n",
        "# ì²­í¬ í¬ê¸° í†µê³„\n",
        "chunk_sizes = [len(doc.page_content) for doc in docs_context_preserved]\n",
        "print(f\"í‰ê·  ì²­í¬ í¬ê¸°: {sum(chunk_sizes) / len(chunk_sizes):.0f} ë¬¸ì\")\n",
        "print(f\"ìµœì†Œ ì²­í¬ í¬ê¸°: {min(chunk_sizes)} ë¬¸ì\")\n",
        "print(f\"ìµœëŒ€ ì²­í¬ í¬ê¸°: {max(chunk_sizes)} ë¬¸ì\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ë§¥ë½ ë³´ì¡´ ì„ë² ë”© ì €ì¥ ì™„ë£Œ: models/faiss_vs_rag_iap_v12_context\n",
            "ì´ ë¬¸ì„œ ìˆ˜: 2508\n"
          ]
        }
      ],
      "source": [
        "def create_context_enhanced_embeddings(docs: List[Document], output_path: str):\n",
        "    \"\"\"ë§¥ë½ ë³´ì¡´ í–¥ìƒëœ ì„ë² ë”© ìƒì„± ë° ì €ì¥\"\"\"\n",
        "    \n",
        "    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
        "    embedding_model = OllamaEmbeddings(model=\"exaone3.5:latest\")\n",
        "    \n",
        "    # FAISS ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±\n",
        "    db = FAISS.from_documents(docs, embedding_model)\n",
        "    \n",
        "    # ì¶”ê°€ ì¸ë±ìŠ¤ ìƒì„± (í‚¤ì›Œë“œ ê¸°ë°˜)\n",
        "    keyword_docs = []\n",
        "    for doc in docs:\n",
        "        keywords = doc.metadata.get('keywords', [])\n",
        "        for keyword in keywords:\n",
        "            # í‚¤ì›Œë“œë³„ë¡œ ë³„ë„ ë¬¸ì„œ ìƒì„±\n",
        "            keyword_doc = Document(\n",
        "                page_content=f\"{keyword}: {doc.page_content[:300]}...\",\n",
        "                metadata={\n",
        "                    **doc.metadata,\n",
        "                    \"keyword\": keyword,\n",
        "                    \"is_keyword_doc\": True\n",
        "                }\n",
        "            )\n",
        "            keyword_docs.append(keyword_doc)\n",
        "    \n",
        "    # í‚¤ì›Œë“œ ë¬¸ì„œë„ ì„ë² ë”©ì— ì¶”ê°€\n",
        "    if keyword_docs:\n",
        "        keyword_db = FAISS.from_documents(keyword_docs, embedding_model)\n",
        "        # ê¸°ì¡´ DBì™€ ë³‘í•©\n",
        "        db.merge_from(keyword_db)\n",
        "    \n",
        "    # ì €ì¥\n",
        "    db.save_local(output_path)\n",
        "    print(f\"âœ… ë§¥ë½ ë³´ì¡´ ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
        "    print(f\"ì´ ë¬¸ì„œ ìˆ˜: {len(docs) + len(keyword_docs)}\")\n",
        "    \n",
        "    return db\n",
        "\n",
        "# ë§¥ë½ ë³´ì¡´ ì„ë² ë”© ìƒì„±\n",
        "output_dir = \"models/faiss_vs_rag_iap_v12_context\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "context_enhanced_db = create_context_enhanced_embeddings(docs_context_preserved, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ë§¥ë½ ë³´ì¡´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===\n",
            "\\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: PNS\n",
            "\\n1. ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼ (3ê°œ):\n",
            "  1. . \"...\n",
            "     í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "     ë¶„í•  ë°©ë²•: recursive_split\n",
            "  2. PurchaseData: . \"......\n",
            "     í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "     ë¶„í•  ë°©ë²•: recursive_split\n",
            "  3. ProductDetail: . \"......\n",
            "     í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "     ë¶„í•  ë°©ë²•: recursive_split\n",
            "\\n2. MMR ê²€ìƒ‰ ê²°ê³¼ (3ê°œ):\n",
            "  1. . \"...\n",
            "     í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "     ë¶„í•  ë°©ë²•: recursive_split\n",
            "  2. PurchaseData: . \"......\n",
            "     í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "     ë¶„í•  ë°©ë²•: recursive_split\n",
            "  3. . ë‹¤ë§Œ...\n",
            "     í‚¤ì›Œë“œ: ['ProrationMode', 'launchPurchaseFlow', 'PurchaseFlowParams', 'ProductDetail', 'IapResult', 'queryProductDetailAsync', 'SubscriptionNotification', 'PNS', 'SNS', 'PurchaseData', 'PurchaseClient']\n",
            "     ë¶„í•  ë°©ë²•: recursive_split\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ë§¥ë½ ë³´ì¡´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "print(\"=== ë§¥ë½ ë³´ì¡´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===\")\n",
        "\n",
        "# ì„ë² ë”© ë¡œë“œ\n",
        "embedding_model = OllamaEmbeddings(model=\"exaone3.5:latest\")\n",
        "loaded_db = FAISS.load_local(\n",
        "    folder_path=output_dir,\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True,\n",
        ")\n",
        "\n",
        "# ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ì‹ í…ŒìŠ¤íŠ¸\n",
        "test_queries = [\n",
        "    # \"launchPurchaseFlow()\",\n",
        "    # \"launchPurchaseFlow\",\n",
        "    # \"êµ¬ë§¤ ìš”ì²­ í•¨ìˆ˜\",\n",
        "    # \"PurchaseClient\",\n",
        "    # \"queryProductDetailAsync\",\n",
        "    # \"ì¸ì•±ê²°ì œ êµ¬ë§¤ í”„ë¡œì„¸ìŠ¤\",\n",
        "    # \"IapResult\",\n",
        "    # \"PurchaseData\",\n",
        "    \"PNS\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\\\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}\")\n",
        "    \n",
        "    # 1. ì§ì ‘ similarity ê²€ìƒ‰\n",
        "    results_direct = loaded_db.similarity_search(query, k=3)\n",
        "    print(f\"\\\\n1. ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼ ({len(results_direct)}ê°œ):\")\n",
        "    for i, doc in enumerate(results_direct, 1):\n",
        "        print(f\"  {i}. {doc.page_content}...\")\n",
        "        print(f\"     í‚¤ì›Œë“œ: {doc.metadata.get('keywords', [])}\")\n",
        "        print(f\"     ë¶„í•  ë°©ë²•: {doc.metadata.get('split_method', 'unknown')}\")\n",
        "    \n",
        "    # 2. MMR ê²€ìƒ‰\n",
        "    retriever_mmr = loaded_db.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\"k\": 3, \"fetch_k\": 8, \"lambda_mult\": 0.6}\n",
        "    )\n",
        "    results_mmr = retriever_mmr.invoke(query)\n",
        "    print(f\"\\\\n2. MMR ê²€ìƒ‰ ê²°ê³¼ ({len(results_mmr)}ê°œ):\")\n",
        "    for i, doc in enumerate(results_mmr, 1):\n",
        "        print(f\"  {i}. {doc.page_content}...\")\n",
        "        print(f\"     í‚¤ì›Œë“œ: {doc.metadata.get('keywords', [])}\")\n",
        "        print(f\"     ë¶„í•  ë°©ë²•: {doc.metadata.get('split_method', 'unknown')}\")\n",
        "    \n",
        "    print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë§¥ë½ ë³´ì¡´ RAG ì²´ì¸ ìƒì„±\n",
        "print(\"=== ë§¥ë½ ë³´ì¡´ RAG ì²´ì¸ ìƒì„± ===\")\n",
        "\n",
        "# LLM ì„¤ì •\n",
        "llm = ChatOllama(model=\"exaone3.5:latest\", temperature=0.3)\n",
        "\n",
        "# ê²€ìƒ‰ê¸° ì„¤ì • (ë§¥ë½ ë³´ì¡´ ê²€ìƒ‰)\n",
        "retriever = loaded_db.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 5, \"fetch_k\": 12, \"lambda_mult\": 0.7}\n",
        ")\n",
        "\n",
        "# ë§¥ë½ ë³´ì¡´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "prompt_template = \"\"\"\n",
        "ë‹¹ì‹ ì€ ì›ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:\n",
        "1. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”\n",
        "2. ì½”ë“œ ì˜ˆì‹œê°€ ìˆë‹¤ë©´ í¬í•¨í•´ì£¼ì„¸ìš”\n",
        "3. ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
        "4. ê°œë°œì ê´€ì ì—ì„œ ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”\n",
        "5. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ \"í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”\n",
        "6. í•¨ìˆ˜ëª…ì´ë‚˜ APIëª…ì´ ì–¸ê¸‰ëœ ê²½ìš° êµ¬ì²´ì ì¸ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
        "7. ìŠ¤í™ì´ë‚˜ ê·œê²© ì •ë³´ê°€ ìˆë‹¤ë©´ ì •í™•íˆ í¬í•¨í•´ì£¼ì„¸ìš”\n",
        "8. ì „ì²´ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”\n",
        "\n",
        "ì»¨í…ìŠ¤íŠ¸:\n",
        "{context}\n",
        "\n",
        "ì§ˆë¬¸: {question}\n",
        "\n",
        "ë‹µë³€:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "# RAG ì²´ì¸ êµ¬ì„±\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"âœ… ë§¥ë½ ë³´ì¡´ RAG ì²´ì¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë§¥ë½ ë³´ì¡´ RAG ì²´ì¸ í…ŒìŠ¤íŠ¸\n",
        "print(\"=== ë§¥ë½ ë³´ì¡´ RAG ì²´ì¸ í…ŒìŠ¤íŠ¸ ===\")\n",
        "\n",
        "test_questions = [\n",
        "    \"launchPurchaseFlow() í•¨ìˆ˜ëŠ” ì–¸ì œ ì‚¬ìš©ë˜ë‚˜ìš”?\",\n",
        "    \"PurchaseClient ì´ˆê¸°í™” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "    \"queryProductDetailAsync API ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”\",\n",
        "    \"IapResultì™€ PurchaseDataì˜ ì°¨ì´ì ì€?\",\n",
        "    \"ì¸ì•±ê²°ì œ êµ¬ë§¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”\",\n",
        "    \"PNS(Push Notification Service)ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "]\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\\\nğŸ“ ì§ˆë¬¸ {i}: {question}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    try:\n",
        "        answer = rag_chain.invoke(question)\n",
        "        print(answer)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "    \n",
        "    print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ (ë§¥ë½ ë³´ì¡´)\n",
        "def analyze_context_search_results(question: str, top_k: int = 5):\n",
        "    \"\"\"ë§¥ë½ ë³´ì¡´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\"\"\"\n",
        "    print(f\"ğŸ” ì§ˆë¬¸: {question}\")\n",
        "    print(f\"ğŸ“Š ìƒìœ„ {top_k}ê°œ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\\\\n\")\n",
        "    \n",
        "    # ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
        "    docs = retriever.invoke(question)\n",
        "    \n",
        "    for i, doc in enumerate(docs[:top_k], 1):\n",
        "        print(f\"ğŸ“„ ê²°ê³¼ {i}:\")\n",
        "        print(f\"   íƒ€ì…: {doc.metadata.get('type', 'unknown')}\")\n",
        "        print(f\"   ì†ŒìŠ¤: {doc.metadata.get('source', 'unknown')}\")\n",
        "        print(f\"   í‚¤ì›Œë“œ: {doc.metadata.get('keywords', [])}\")\n",
        "        print(f\"   ì½”ë“œ í¬í•¨: {doc.metadata.get('has_code', False)}\")\n",
        "        print(f\"   í•¨ìˆ˜ í¬í•¨: {doc.metadata.get('has_function', False)}\")\n",
        "        print(f\"   ë¶„í•  ë°©ë²•: {doc.metadata.get('split_method', 'unknown')}\")\n",
        "        print(f\"   ì²­í¬ í¬ê¸°: {len(doc.page_content)} ë¬¸ì\")\n",
        "        print(f\"   ë‚´ìš©: {doc.page_content[:200]}...\")\n",
        "        print(\"   \" + \"-\" * 50)\n",
        "    \n",
        "    print(f\"\\\\nâœ… ì´ {len(docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ í…ŒìŠ¤íŠ¸\n",
        "analyze_context_search_results(\"launchPurchaseFlow\", top_k=3)\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "analyze_context_search_results(\"PurchaseClient\", top_k=3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
